{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from os.path import isfile, isdir\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Union\n",
    "import gc\n",
    "import copy\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import configparser\n",
    "import time\n",
    "\n",
    "import quantus\n",
    "from captum.attr import *\n",
    "\n",
    "# import config_vae_inference_local as config\n",
    "import vae_models, bayesian_models\n",
    "import vae_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, image_dir, device, normalize):\n",
    "        self.dataset = glob.glob(f\"{os.path.join(image_dir,'*')}\")\n",
    "        self.device = device\n",
    "        self.normalize = normalize\n",
    "        # print(f\"Test instances: {len(self.dataset)}\")\n",
    "        # print(self.dataset[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.dataset[index])\n",
    "        image_float_np = np.float32(image) / 255\n",
    "\n",
    "        # input_tensor = preprocess_image(image_float_np, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        input_tensor = self.get_transform(self.normalize)(image_float_np)\n",
    "        plot_tensor = self.get_transform(False)(image_float_np)\n",
    "        input_tensor = input_tensor.to(self.device)\n",
    "        plot_tensor = plot_tensor.to(self.device)\n",
    "        return [input_tensor,plot_tensor], 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def get_transform(self, normalize):\n",
    "        transforms = []\n",
    "        transforms.append(T.ToTensor())\n",
    "        # transforms.append(T.ConvertImageDtype(torch.float))\n",
    "        if normalize:\n",
    "            transforms.append(T.Normalize(mean=[0.4500, 0.4373, 0.4494], std=[0.2248, 0.2249, 0.2280]))\n",
    "        return T.Compose(transforms)\n",
    "\n",
    "    # def get_transform2(self):\n",
    "    #     transforms = []\n",
    "    #     transforms.append(T.ToTensor())\n",
    "    #     return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explainer_wrapper(**kwargs):\n",
    "    \"\"\"Wrapper for explainer functions.\"\"\"\n",
    "    if kwargs[\"method\"] == \"Saliency\":\n",
    "        return saliency_explainer(**kwargs)\n",
    "    elif kwargs[\"method\"] == \"IntegratedGradients\":\n",
    "        return intgrad_explainer(**kwargs)\n",
    "    elif kwargs[\"method\"] == \"FusionGrad\":\n",
    "        return fusiongrad_explainer(**kwargs)\n",
    "    elif kwargs[\"method\"] == \"GradientShap\":\n",
    "        return gradshap_explainer(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"Pick an explaination function that exists.\")\n",
    "\n",
    "\n",
    "def saliency_explainer(\n",
    "    model, inputs, targets, abs=False, normalise=False, *args, **kwargs\n",
    ") -> np.array:\n",
    "    \"\"\"Wrapper aorund captum's Saliency implementation.\"\"\"\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Set model in evaluate mode.\n",
    "    model.to(kwargs.get(\"device\", None))\n",
    "    model.eval()\n",
    "\n",
    "    if not isinstance(inputs, torch.Tensor):\n",
    "        inputs = (\n",
    "            torch.Tensor(inputs)\n",
    "            .reshape(\n",
    "                -1,\n",
    "                kwargs.get(\"nr_channels\", 3),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "            )\n",
    "            .to(kwargs.get(\"device\", None))\n",
    "        )\n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = (\n",
    "            torch.as_tensor(targets).long().to(kwargs.get(\"device\", None))\n",
    "        )  # inputs = inputs.reshape(-1, 3, 28, 28)\n",
    "\n",
    "    assert (\n",
    "        len(np.shape(inputs)) == 4\n",
    "    ), \"Inputs should be shaped (nr_samples, nr_channels, img_size, img_size) e.g., (1, 3, 28, 28).\"\n",
    "\n",
    "    explanation = (\n",
    "        Saliency(model)\n",
    "        .attribute(inputs, targets, abs=abs)\n",
    "        .sum(axis=1)\n",
    "        .reshape(-1, kwargs.get(\"img_size\", 28), kwargs.get(\"img_size\", 28))\n",
    "        .cpu()\n",
    "        .data\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if normalise:\n",
    "        explanation = quantus.normalise_func.normalise_by_negative(explanation)\n",
    "\n",
    "    if isinstance(explanation, torch.Tensor):\n",
    "        if explanation.requires_grad:\n",
    "            return explanation.cpu().detach().numpy()\n",
    "        return explanation.cpu().numpy()\n",
    "\n",
    "    return explanation\n",
    "\n",
    "\n",
    "def intgrad_explainer(\n",
    "    model, inputs, targets, abs=False, normalise=False, *args, **kwargs\n",
    ") -> np.array:\n",
    "    \"\"\"Wrapper aorund captum's Integrated Gradients implementation.\"\"\"\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Set model in evaluate mode.\n",
    "    model.to(kwargs.get(\"device\", None))\n",
    "    model.eval()\n",
    "\n",
    "    if not isinstance(inputs, torch.Tensor):\n",
    "        inputs = (\n",
    "            torch.Tensor(inputs)\n",
    "            .reshape(\n",
    "                -1,\n",
    "                kwargs.get(\"nr_channels\", 3),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "            )\n",
    "            .to(kwargs.get(\"device\", None))\n",
    "        )\n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = torch.as_tensor(targets).long().to(kwargs.get(\"device\", None))\n",
    "\n",
    "    assert (\n",
    "        len(np.shape(inputs)) == 4\n",
    "    ), \"Inputs should be shaped (nr_samples, nr_channels, img_size, img_size) e.g., (1, 3, 28, 28).\"\n",
    "\n",
    "    explanation = (\n",
    "        IntegratedGradients(model)\n",
    "        .attribute(\n",
    "            inputs=inputs,\n",
    "            target=targets,\n",
    "            # baselines=torch.zeros_like(inputs),\n",
    "            baselines=torch.rand_like(inputs),\n",
    "            # baselines = torch.ones_like(inputs),\n",
    "            n_steps=10,\n",
    "            method=\"riemann_trapezoid\",\n",
    "        )\n",
    "        .sum(axis=1)\n",
    "        .reshape(-1, kwargs.get(\"img_size\", 28), kwargs.get(\"img_size\", 28))\n",
    "        .cpu()\n",
    "        .data\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if normalise:\n",
    "        explanation = quantus.normalise_func.normalise_by_negative(explanation)\n",
    "\n",
    "    if isinstance(explanation, torch.Tensor):\n",
    "        if explanation.requires_grad:\n",
    "            return explanation.cpu().detach().numpy()\n",
    "        return explanation.cpu().numpy()\n",
    "\n",
    "    return explanation\n",
    "\n",
    "\n",
    "def gradshap_explainer(\n",
    "    model, inputs, targets, abs=False, normalise=False, *args, **kwargs\n",
    ") -> np.array:\n",
    "    \"\"\"Wrapper aorund captum's GradShap implementation.\"\"\"\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Set model in evaluate mode.\n",
    "    model.to(kwargs.get(\"device\", None))\n",
    "    model.eval()\n",
    "\n",
    "    if not isinstance(inputs, torch.Tensor):\n",
    "        inputs = (\n",
    "            torch.Tensor(inputs)\n",
    "            .reshape(\n",
    "                -1,\n",
    "                kwargs.get(\"nr_channels\", 3),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "            )\n",
    "            .to(kwargs.get(\"device\", None))\n",
    "        )\n",
    "\n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = torch.as_tensor(targets).long().to(kwargs.get(\"device\", None))\n",
    "\n",
    "    assert (\n",
    "        len(np.shape(inputs)) == 4\n",
    "    ), \"Inputs should be shaped (nr_samples, nr_channels, img_size, img_size) e.g., (1, 3, 28, 28).\"\n",
    "\n",
    "    baselines = torch.zeros_like(inputs).to(kwargs.get(\"device\", None))\n",
    "    explanation = (\n",
    "        GradientShap(model)\n",
    "        .attribute(inputs=inputs, target=targets, baselines=baselines)\n",
    "        .sum(axis=1)\n",
    "        .reshape(-1, kwargs.get(\"img_size\", 28), kwargs.get(\"img_size\", 28))\n",
    "        .cpu()\n",
    "        .data\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if normalise:\n",
    "        explanation = quantus.normalise_func.normalise_by_negative(explanation)\n",
    "\n",
    "    if isinstance(explanation, torch.Tensor):\n",
    "        if explanation.requires_grad:\n",
    "            return explanation.cpu().detach().numpy()\n",
    "        return explanation.cpu().numpy()\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def fusiongrad_explainer(\n",
    "    model, inputs, targets, abs=False, normalise=False, *args, **kwargs\n",
    ") -> np.array:\n",
    "    \"\"\"Wrapper aorund captum's FusionGrad implementation.\"\"\"\n",
    "\n",
    "    std = kwargs.get(\"std\", 0.5)\n",
    "    mean = kwargs.get(\"mean\", 1.0)\n",
    "    n = kwargs.get(\"n\", 10)\n",
    "    m = kwargs.get(\"m\", 10)\n",
    "    sg_std = kwargs.get(\"sg_std\", 0.5)\n",
    "    sg_mean = kwargs.get(\"sg_mean\", 0.0)\n",
    "    posterior_mean = kwargs.get(\"posterior_mean\", None)\n",
    "    noise_type = kwargs.get(\"noise_type\", \"multiplicative\")\n",
    "    clip = kwargs.get(\"clip\", False)\n",
    "\n",
    "    def _sample(model, posterior_mean, std, distribution=None, noise_type=\"multiplicative\"):\n",
    "        \"\"\"Implmentation to sample a model.\"\"\"\n",
    "\n",
    "        # Load model params.\n",
    "        model.load_state_dict(posterior_mean)\n",
    "\n",
    "        # If std is not zero, loop over each layer and add Gaussian noise.\n",
    "        if not std == 0.0:\n",
    "            with torch.no_grad():\n",
    "                for layer in model.parameters():\n",
    "                    if noise_type == \"additive\":\n",
    "                        layer.add_(distribution.sample(layer.size()).to(layer.device))\n",
    "                    elif noise_type == \"multiplicative\":\n",
    "                        layer.mul_(distribution.sample(layer.size()).to(layer.device))\n",
    "                    else:\n",
    "                        print(\n",
    "                            \"Set NoiseGrad attribute 'noise_type' to either 'additive' or 'multiplicative' (str).\"\n",
    "                        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    # Creates a normal (also called Gaussian) distribution.\n",
    "    distribution = torch.distributions.normal.Normal(\n",
    "        loc=torch.as_tensor(mean, dtype=torch.float),\n",
    "        scale=torch.as_tensor(std, dtype=torch.float),\n",
    "    )\n",
    "\n",
    "    # Set model in evaluate mode.\n",
    "    model.to(kwargs.get(\"device\", None))\n",
    "    model.eval()\n",
    "\n",
    "    if not isinstance(inputs, torch.Tensor):\n",
    "        inputs = (\n",
    "            torch.Tensor(inputs)\n",
    "            .reshape(\n",
    "                -1,\n",
    "                kwargs.get(\"nr_channels\", 3),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "            )\n",
    "            .to(kwargs.get(\"device\", None))\n",
    "        )\n",
    "    if not isinstance(targets, torch.Tensor):\n",
    "        targets = torch.as_tensor(targets).long().to(kwargs.get(\"device\", None))\n",
    "\n",
    "    assert (\n",
    "        len(np.shape(inputs)) == 4\n",
    "    ), \"Inputs should be shaped (nr_samples, nr_channels, img_size, img_size) e.g., (1, 3, 28, 28).\"\n",
    "\n",
    "    if inputs.shape[0] > 1:\n",
    "        explanation = torch.zeros(\n",
    "            (\n",
    "                n,\n",
    "                m,\n",
    "                inputs.shape[0],\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "                kwargs.get(\"img_size\", 28),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        explanation = torch.zeros(\n",
    "            (n, m, kwargs.get(\"img_size\", 28), kwargs.get(\"img_size\", 28))\n",
    "        )\n",
    "\n",
    "    for i in range(n):\n",
    "        model = _sample(\n",
    "            model=model,\n",
    "            posterior_mean=posterior_mean,\n",
    "            std=std,\n",
    "            distribution=distribution,\n",
    "            noise_type=noise_type,\n",
    "        )\n",
    "        for j in range(m):\n",
    "            inputs_noisy = inputs + torch.randn_like(inputs) * sg_std + sg_mean\n",
    "            if clip:\n",
    "                inputs_noisy = torch.clip(inputs_noisy, min=0.0, max=1.0)\n",
    "\n",
    "            explanation[i][j] = (\n",
    "                Saliency(model)\n",
    "                .attribute(inputs_noisy, targets, abs=abs)\n",
    "                .sum(axis=1)\n",
    "                .reshape(-1, kwargs.get(\"img_size\", 28), kwargs.get(\"img_size\", 28))\n",
    "                .cpu()\n",
    "                .data\n",
    "            )\n",
    "\n",
    "    explanation = explanation.mean(axis=(0, 1))\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if normalise:\n",
    "        explanation = quantus.normalise_func.normalise_by_negative(explanation)\n",
    "\n",
    "    if isinstance(explanation, torch.Tensor):\n",
    "        if explanation.requires_grad:\n",
    "            return explanation.cpu().detach().numpy()\n",
    "        return explanation.cpu().numpy()\n",
    "\n",
    "    return explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce explanations and empty cache to to survive memory-wise.\n",
    "def get_xai_explanations(x_batch, y_batch, model, device, model_type, bnn_reps=10):\n",
    "    # Saliency.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    res = [saliency_explainer(model=model.to(device),\n",
    "                                        inputs=x_batch,\n",
    "                                        targets=y_batch,\n",
    "                                        **{\"device\": device},\n",
    "                                        ) for _ in range(bnn_reps)]\n",
    "    a_batch_saliency = np.mean(res, axis=0)\n",
    "    a_batch_saliency_std = np.std(res, axis=0)\n",
    "    # GradShap.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    res = [gradshap_explainer(model=model.to(device), \n",
    "                                        inputs=x_batch,\n",
    "                                        targets=y_batch, \n",
    "                                        **{\"device\": device},\n",
    "                                        ) for _ in range(bnn_reps)]\n",
    "    a_batch_gradshap = np.mean(res, axis=0)\n",
    "    a_batch_gradshap_std = np.std(res, axis=0)\n",
    "    # Integrated Gradients.\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    res = [intgrad_explainer(model=model.to(device),\n",
    "                                        inputs=x_batch,\n",
    "                                        targets=y_batch,\n",
    "                                        **{\"device\": device},\n",
    "                                        ) for _ in range(bnn_reps)]\n",
    "    a_batch_intgrad = np.mean(res, axis=0)\n",
    "    a_batch_intgrad_std = np.std(res, axis=0)\n",
    "\n",
    "    # FusionGrad\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    posterior_mean = copy.deepcopy(model.to(device).state_dict())\n",
    "    res = [fusiongrad_explainer(model=model.to(device), \n",
    "                                            inputs=x_batch, \n",
    "                                            targets=y_batch, \n",
    "                                            **{\"posterior_mean\": posterior_mean, \"mean\": 1.0, \"std\": 0.5, \n",
    "                                                \"sg_mean\": 0.0, \"sg_std\": 0.5, \"n\": 25, \"m\": 25, \n",
    "                                                \"noise_type\": \"multiplicative\", \"device\": device}) for _ in range(bnn_reps)]\n",
    "\n",
    "    a_batch_fusiongrad = np.mean(res, axis=0)\n",
    "    a_batch_fusiongrad_std = np.std(res, axis=0)\n",
    "    # Save explanations to file.\n",
    "    if model_type == \"BNN\":\n",
    "        explanations = {\n",
    "            \"mean(SAL)\": a_batch_saliency,\n",
    "            \"std(SAL)\": a_batch_saliency_std,\n",
    "            \"mean(GS)\": a_batch_gradshap,\n",
    "            \"std(GS)\": a_batch_gradshap_std,\n",
    "            \"mean(IG)\": a_batch_intgrad,\n",
    "            \"std(IG)\": a_batch_intgrad_std,\n",
    "            \"mean(FG)\": a_batch_fusiongrad,\n",
    "            \"std(FG)\": a_batch_fusiongrad_std\n",
    "        }\n",
    "    else:\n",
    "        explanations = {\n",
    "            \"SAL\": a_batch_saliency,\n",
    "            \"GS\": a_batch_gradshap,\n",
    "            \"IG\": a_batch_intgrad,\n",
    "            \"FG\": a_batch_fusiongrad\n",
    "        }\n",
    "\n",
    "    # explanations_std = {\n",
    "    #     \"Saliency_std\": a_batch_saliency_std,\n",
    "    #     \"GradientShap_std\": a_batch_gradshap_std,\n",
    "    #     \"IntegratedGradients_std\": a_batch_intgrad_std,\n",
    "    #     # \"FusionGrad\": a_batch_fusiongrad\n",
    "    # }\n",
    "\n",
    "    return explanations\n",
    "\n",
    "\n",
    "def get_xai_methods_and_metrics(explanations, num_classes, subset_size=14, perturb_baseline=\"black\", avg_sensitivity_samples=10, disable_warnings=True):\n",
    "    xai_methods = list(explanations.keys())\n",
    "\n",
    "    metrics = {\n",
    "    \"Robustness\": quantus.AvgSensitivity(\n",
    "        nr_samples=avg_sensitivity_samples,\n",
    "        lower_bound=0.2,\n",
    "        norm_numerator=quantus.norm_func.fro_norm,\n",
    "        norm_denominator=quantus.norm_func.fro_norm,\n",
    "        perturb_func=quantus.perturb_func.uniform_noise,\n",
    "        similarity_func=quantus.similarity_func.difference,\n",
    "        abs=False,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Faithfulness\": quantus.FaithfulnessCorrelation(\n",
    "        nr_runs=10,\n",
    "        subset_size=subset_size,\n",
    "        perturb_baseline=perturb_baseline,\n",
    "        perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "        similarity_func=quantus.similarity_func.correlation_pearson,\n",
    "        abs=False,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Complexity\": quantus.Sparseness(\n",
    "        abs=True,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Randomisation\": quantus.RandomLogit(\n",
    "        num_classes=num_classes,\n",
    "        similarity_func=quantus.similarity_func.ssim,\n",
    "        abs=True,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    )}\n",
    "    # )},\n",
    "    # \"Sufficiency\": quantus.Sufficiency(\n",
    "    #     threshold=0.6,\n",
    "    #     return_aggregate=False,\n",
    "    #     disable_warnings=disable_warnings\n",
    "    # ),\n",
    "    # \"Consistency\": quantus.Consistency(\n",
    "    #     discretise_func=quantus.discretise_func.top_n_sign,\n",
    "    #     return_aggregate=False,\n",
    "    #     disable_warnings=disable_warnings)\n",
    "    # }\n",
    "    \n",
    "\n",
    "    return xai_methods, metrics\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explanations(x_batch, y_batch, explanations, probabilities, num_classes, output_dir, epoch):\n",
    "    # i_max = 1\n",
    "    # for idx,x in enumerate(x_batch.cpu().numpy()):\n",
    "    for idx,x in enumerate(x_batch):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2+len(explanations), figsize=(15, 4))\n",
    "        # axes[0].imshow(np.moveaxis(quantus.normalise_func.denormalise(x_batch[index].cpu().numpy(), mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225])), 0, -1), vmin=0.0, vmax=1.0)\n",
    "        # img\n",
    "        axes[0].imshow(np.moveaxis(x, 0, -1), vmin=0.0, vmax=1.0)\n",
    "        axes[0].title.set_text(f\"class {y_batch[idx].item()}\")\n",
    "        axes[0].axis(\"off\")\n",
    "        # probability bar \n",
    "        axes[1].bar(np.arange(num_classes), np.array([probabilities[idx][0],probabilities[idx][1]]), color='red')\n",
    "        axes[1].set_xticks(np.arange(num_classes))\n",
    "        axes[1].set_ylim([0, 1])\n",
    "        # explanations\n",
    "        for i, (k, v) in enumerate(explanations.items()):\n",
    "            axes[i+2].imshow(quantus.normalise_func.normalise_by_negative(explanations[k][idx].reshape(28, 28)), cmap=\"seismic\", vmin=-1.0, vmax=1.0)\n",
    "            axes[i+2].title.set_text(f\"{k}\")\n",
    "            axes[i+2].axis(\"off\")\n",
    "\n",
    "        plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{idx}_explanation.jpg\")\n",
    "        plt.savefig(plot_loc)\n",
    "        plt.close('all')\n",
    "\n",
    "\n",
    "def plot_explanations_with_sums(x_batch, y_batch, explanations, probabilities, num_classes, output_dir, epoch, num_forward_passes, model_type=\"BNN\", scale_factor=7):\n",
    "    y_indices_rowsums = np.linspace(0,x_batch[0].shape[1]-1,x_batch[0].shape[1]).astype(int)\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    for idx,x in enumerate(x_batch):\n",
    "        if model_type == \"BNN\":\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2+len(explanations), figsize=(16, 2), constrained_layout = True) #, gridspec_kw={'height_ratios': [12 if i != 1 else 4 for i in range(2+len(explanations))]})\n",
    "        else:\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=1+int(len(explanations)), figsize=(6, 2), constrained_layout = True)\n",
    "\n",
    "        # if model_type == \"BNN\":\n",
    "        #     fig.suptitle(\"Explanations for BNN\", fontsize=16)\n",
    "        # else:\n",
    "        #     fig.suptitle(\"Explanations for LeNet\", fontsize=16)\n",
    "\n",
    "        # axes[0].imshow(np.moveaxis(quantus.normalise_func.denormalise(x_batch[index].cpu().numpy(), mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225])), 0, -1), vmin=0.0, vmax=1.0)\n",
    "        # img\n",
    "        #axes[0].imshow(cv2.resize(np.moveaxis(x, 0, -1), (12,12)).astype(np.uint8), vmin=0.0, vmax=1.0)\n",
    "        #  cv2.resize(np.moveaxis(x_batch[0], 0, -1), (20,20))\n",
    "        fig.tight_layout()\n",
    "        axes[0].imshow(np.moveaxis(x, 0, -1), vmin=0.0, vmax=1.0)\n",
    "        axes[0].title.set_text(f\"class {y_batch[idx].item()}\")\n",
    "        axes[0].axis(\"off\")\n",
    "        # probability bar\n",
    "        if model_type == \"BNN\":\n",
    "            axes[1].bar(np.arange(num_classes), np.array([probabilities[idx][0],probabilities[idx][1]]), color='red')\n",
    "            axes[1].set_xticks(np.arange(num_classes))\n",
    "            axes[1].set_ylim([0, 1])\n",
    "            axes[1].set_title(f\"{num_forward_passes} draws\")\n",
    "            # sns.barplot(np.arange(num_classes),np.array([probabilities[idx][0],probabilities[idx][1]]), ax=axes[1])\n",
    "            i = 2\n",
    "        else:\n",
    "            i = 1\n",
    "\n",
    "        for k in explanations.keys():\n",
    "            # skip std plots for lenet (fixed weights)\n",
    "            # if model_type != \"BNN\" and j % 2 != 0:\n",
    "            #     continue\n",
    "            # print(f\"explanations[k][idx]: {k}\")\n",
    "            explanation = explanations[k][idx].reshape(28, 28)\n",
    "            \n",
    "            csum = np.sum(np.clip(explanation,a_min=0,a_max=None), 0)\n",
    "            rsum = np.sum(np.clip(explanation,a_min=0,a_max=None), 1)\n",
    "            csum_scaled = (csum-min(csum))/(max(csum)-min(csum))*scale_factor\n",
    "            rsum_scaled = (rsum-min(rsum))/(max(rsum)-min(rsum))*scale_factor\n",
    "\n",
    "            axes[i].imshow(quantus.normalise_func.normalise_by_negative(explanation), cmap=\"seismic\", vmin=-1.0, vmax=1.0)\n",
    "            axes[i].plot(-abs(csum_scaled), color='blue') #, marker='o') #, mfc='orange')\n",
    "            axes[i].plot(-abs(rsum_scaled), y_indices_rowsums, color='blue') #, marker='o')#, mfc='orange')\n",
    "            # axes[i].plot(csums, color='blue') #, marker='o') #, mfc='orange')\n",
    "            # axes[i].plot(rsums, y_indices_rowsums, color='blue') #, marker='o')#, mfc='orange')\n",
    "            axes[i].title.set_text(f\"{k}\")\n",
    "            axes[i].axis(\"off\")\n",
    "            i += 1\n",
    "\n",
    "        plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{idx}_explanation.jpg\")\n",
    "        plt.savefig(plot_loc)\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bnn_probabilities(image_tensor, class_model, device, num_forward_passes=10):\n",
    "    # print(image_tensor.size()[0])\n",
    "    probs = []\n",
    "    plot_list = []\n",
    "    for tensor in image_tensor:\n",
    "        tensor_unsqueezed = torch.unsqueeze(tensor,0)\n",
    "        with torch.no_grad():\n",
    "            preds = [np.argmax(class_model(tensor_unsqueezed).cpu().numpy()) for _ in range(num_forward_passes)]\n",
    "\n",
    "        mxt_prob = np.mean(preds)\n",
    "        dot_prob = 1 - mxt_prob\n",
    "\n",
    "        probs.append((dot_prob,mxt_prob))\n",
    "\n",
    "        if dot_prob > 0.05 and dot_prob < 0.95:\n",
    "            plot_list.append(True)\n",
    "        else:\n",
    "            plot_list.append(False)\n",
    "    return probs, plot_list\n",
    "\n",
    "# def plot_bnn_probabilities(x_batch, probabilities, output_dir, num_classes, num_forward_passes, epoch, plot_list):\n",
    "#         transform = T.Compose([T.ToPILImage()])\n",
    "        \n",
    "#         for i,tensor in enumerate(x_batch):\n",
    "#             if not plot_list[i]:\n",
    "#                 # print(\"continue\")\n",
    "#                 continue\n",
    "#             # print(\"plottable\")\n",
    "            \n",
    "#             # print(probabilities[i][0])\n",
    "#             plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{i}.jpg\")\n",
    "#             # image = np.array(transform(tensor))\n",
    "#             image = transform(tensor)\n",
    "#             # print(type(image))\n",
    "#             plt.figure()\n",
    "#             fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(num_classes, 2),\n",
    "#                                         gridspec_kw={'width_ratios': [3, 3]})\n",
    "            \n",
    "#             # Show the image and the true label\n",
    "#             # ax1.imshow(image[..., 0], cmap='gray')\n",
    "#             ax1.imshow(image) # , cmap='gray')\n",
    "#             ax1.axis('off')\n",
    "        \n",
    "#             bar = ax2.bar(np.arange(num_classes), np.array([probabilities[i][0],probabilities[i][1]]), color='red')\n",
    "#             # bar[int(true_label)].set_color('green')\n",
    "#             ax2.set_xticks(np.arange(num_classes))\n",
    "#             ax2.set_ylim([0, 1])\n",
    "#             ax2.set_title(f'Probabilities after {num_forward_passes} draws')\n",
    "#             # plt.savefig(os.path.join(plot_loc,\"test_img_{}.png\".format(i)))\n",
    "#             plt.savefig(plot_loc)\n",
    "#             plt.close('all')\n",
    "\n",
    "# def plot_xai_eval(x_batch, y_batch, a_batch_saliency, a_batch_intgrad, output_dir, epoch, plot_list):\n",
    "#     # fig, axes = plt.subplots(nrows=nr_images, ncols=3, figsize=(7.5, int(nr_images*3)))\n",
    "#     for i in range(x_batch.size()[0]):\n",
    "#         if not plot_list[i]:\n",
    "#             # print(\"continue\")\n",
    "#             continue\n",
    "#         # print(\"plottable\")\n",
    "#         plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{i}_xai.jpg\")\n",
    "\n",
    "#         fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(7.5, int(3)))\n",
    "#         axes[0].imshow(rgb2gray(np.reshape(x_batch[i].cpu().numpy(),(28, 28, 3))), cmap=\"gray\") # .astype(np.uint8))# , vmin=0.0, vmax=1.0)#, cmap=\"gray\")\n",
    "#         axes[0].title.set_text(f\"Marker type {y_batch[i].item()}\")\n",
    "#         axes[0].axis(\"off\")\n",
    "#         axes[1].imshow(a_batch_saliency[i], cmap=\"seismic\")\n",
    "#         axes[1].title.set_text(f\"Saliency\")\n",
    "#         axes[1].axis(\"off\")\n",
    "#         axes[2].imshow(a_batch_intgrad[i], cmap=\"seismic\")\n",
    "#         axes[2].title.set_text(f\"Integrated Gradients\")\n",
    "#         axes[2].axis(\"off\")\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(plot_loc)\n",
    "#         plt.close('all')\n",
    "\n",
    "# def rgb2gray(rgb):\n",
    "#     return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain = explanations[\"Saliency\"][0]\n",
    "\n",
    "# # csum = np.sum(explanation, 0)\n",
    "# # rsum = np.sum(explanation, 1)\n",
    "# # csum_scaled = (csum-min(csum))/(max(csum)-min(csum))*scale_factor\n",
    "# # rsum_scaled = (rsum-min(rsum))/(max(rsum)-min(rsum))*scale_factor\n",
    "# a = np.clip(explain,a_min=0,a_max=None)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xai_quantification_results(x_batch, y_batch, class_model, device, xai_methods, xai_metrics, bnn_reps=10):\n",
    "    results = {method : {} for method in xai_methods}\n",
    "\n",
    "    for i,method in enumerate(xai_methods):\n",
    "        # print(f\"i: {i}   method: {method}\")\n",
    "        if (i % 2 != 0):\n",
    "            print(f\"skipping method: {method}\")\n",
    "            continue\n",
    "        for metric, metric_func in xai_metrics.items():\n",
    "\n",
    "            print(f\"Evaluating {metric} of {method} method.\")\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Get scores and append results.\n",
    "            scores = [metric_func(\n",
    "                model=class_model,\n",
    "                x_batch=x_batch,\n",
    "                y_batch=y_batch,\n",
    "                a_batch=None,\n",
    "                device=device,\n",
    "                explain_func=explainer_wrapper,\n",
    "                explain_func_kwargs={\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        class_model.to(device).state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"sg_mean\": 0.0,\n",
    "                    \"sg_std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"m\": 25,\n",
    "                    \"noise_type\": \"multiplicative\",\n",
    "                    \"device\": device,\n",
    "                },\n",
    "            ) for _ in range(1)]\n",
    "            # print(f\"scores: {scores}\")\n",
    "            # print(f\"np.mean(scores,axis=0): {np.mean(scores,axis=0)}\")\n",
    "            results[method][metric] = np.mean(scores,axis=0)\n",
    "\n",
    "            # Empty cache.\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def xai_results_postprocess(xai_methods, xai_metrics, results, output_dir, epoch):\n",
    "    results_agg = {}\n",
    "    for i,method in enumerate(xai_methods):\n",
    "        if i % 2 != 0:\n",
    "            continue\n",
    "        results_agg[method] = {}\n",
    "        for metric, metric_func in xai_metrics.items():\n",
    "            results_agg[method][metric] = np.mean(results[method][metric])\n",
    "\n",
    "    df = pd.DataFrame.from_dict(results_agg)\n",
    "    df = df.T.abs()\n",
    "    df.to_csv(os.path.join(output_dir,f\"df_{epoch}.csv\"))\n",
    "    \n",
    "    # Take inverse ranking for Robustness, since lower is better.\n",
    "    df_normalised = df.loc[:, df.columns != 'Robustness'].apply(lambda x: x / x.max())\n",
    "    df_normalised[\"Robustness\"] = df[\"Robustness\"].min()/df[\"Robustness\"].values\n",
    "    df_normalised_rank = df_normalised.rank()\n",
    "    df_normalised_rank.to_csv(os.path.join(output_dir,f\"df_normalised_rank_{epoch}.csv\"))\n",
    "    return df, df_normalised_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import quantus\n",
    "\n",
    "# quantus.AVAILABLE_PERTURBATION_FUNCTIONS\n",
    "# quantus.AVAILABLE_SIMILARITY_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    metrics = {\n",
    "    \"Robustness\": quantus.AvgSensitivity(\n",
    "        nr_samples=avg_sensitivity_samples,\n",
    "        lower_bound=0.2,\n",
    "        norm_numerator=quantus.norm_func.fro_norm,\n",
    "        norm_denominator=quantus.norm_func.fro_norm,\n",
    "        perturb_func=quantus.perturb_func.uniform_noise,\n",
    "        similarity_func=quantus.similarity_func.difference,\n",
    "        abs=False,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Faithfulness\": quantus.FaithfulnessCorrelation(\n",
    "        nr_runs=10,\n",
    "        subset_size=subset_size,\n",
    "        perturb_baseline=perturb_baseline,\n",
    "        perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "        similarity_func=quantus.similarity_func.correlation_pearson,\n",
    "        abs=False,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Complexity\": quantus.Sparseness(\n",
    "        abs=True,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    ),\n",
    "    \"Randomisation\": quantus.RandomLogit(\n",
    "        num_classes=num_classes,\n",
    "        similarity_func=quantus.similarity_func.ssim,\n",
    "        abs=True,\n",
    "        normalise=False,\n",
    "        aggregate_func=np.mean,\n",
    "        return_aggregate=True,\n",
    "        disable_warnings=disable_warnings,\n",
    "    )}\n",
    "    # )},\n",
    "    # \"Sufficiency\": quantus.Sufficiency(\n",
    "    #     threshold=0.6,\n",
    "    #     return_aggregate=False,\n",
    "    #     disable_warnings=disable_warnings\n",
    "    # ),\n",
    "    # \"Consistency\": quantus.Consistency(\n",
    "    #     discretise_func=quantus.discretise_func.top_n_sign,\n",
    "    #     return_aggregate=False,\n",
    "    #     disable_warnings=disable_warnings)\n",
    "    # }\n",
    "\"\"\"\n",
    "\n",
    "# for i,method in enumerate(xai_methods):\n",
    "#     if (i % 2 != 0):\n",
    "#         print(f\"skipping method: {method}\")\n",
    "#         continue\n",
    "#     # for metric, metric_func in xai_metrics.items():\n",
    "#     print(f\"method: {method}\")\n",
    "#     print(f\"metric_func: {metric_func}\")        \n",
    "#     scores = [metric_func(\n",
    "#                     model=class_model,\n",
    "#                     x_batch=x_batch,\n",
    "#                     y_batch=y_batch,\n",
    "#                     a_batch=None,\n",
    "#                     device=device,\n",
    "#                     explain_func=explainer_wrapper,\n",
    "#                     explain_func_kwargs={\n",
    "#                         \"method\": method,\n",
    "#                         \"posterior_mean\": copy.deepcopy(\n",
    "#                             class_model.to(device).state_dict()\n",
    "#                         ),\n",
    "#                         \"mean\": 1.0,\n",
    "#                         \"std\": 0.5,\n",
    "#                         \"sg_mean\": 0.0,\n",
    "#                         \"sg_std\": 0.5,\n",
    "#                         \"n\": 25,\n",
    "#                         \"m\": 25,\n",
    "#                         \"noise_type\": \"multiplicative\",\n",
    "#                         \"device\": device,\n",
    "#                     },\n",
    "#                 ) for _ in range(1)]\n",
    "\n",
    "# \"Complexity\": quantus.Sparseness(\n",
    "#         abs=True,\n",
    "#         normalise=False,\n",
    "#         aggregate_func=np.mean,\n",
    "#         return_aggregate=True,\n",
    "#         disable_warnings=disable_warnings,\n",
    "#     )\n",
    "\n",
    "\n",
    "# range: 0-ln(2)? https://arxiv.org/pdf/2005.00631.pdf section 5\n",
    "\n",
    "# def get_complexity_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, complex_score_result, bnn_reps=1,\n",
    "#                             save_results_to_dataframe=True, disable_warnings=True):\n",
    "#     print(\"Generating complexity results\")\n",
    "    \n",
    "#     result = complex_score_result\n",
    "\n",
    "#     for i, (method, attr) in enumerate(explanations.items()):\n",
    "#         if i % 2 != 0:\n",
    "#             # print(\"skipping method: {method}\")\n",
    "#             continue\n",
    "#         metric_func = quantus.Sparseness(abs=True,\n",
    "#                                             normalise=False,\n",
    "#                                             aggregate_func=np.mean,\n",
    "#                                             return_aggregate=True,\n",
    "#                                             disable_warnings=disable_warnings,\n",
    "#                                         )\n",
    "#         # print(f\"metric: {metric}\")\n",
    "#         # score = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "#         score = np.mean([metric_func(\n",
    "#             model=model,\n",
    "#             x_batch=x_batch,\n",
    "#             y_batch=y_batch,\n",
    "#             a_batch=None,\n",
    "#             device=device,\n",
    "#             explain_func=explainer_wrapper,\n",
    "#             explain_func_kwargs={\n",
    "#                 \"method\": method,\n",
    "#                 \"posterior_mean\": copy.deepcopy(\n",
    "#                     model.to(device).state_dict()\n",
    "#                 ),\n",
    "#                 \"mean\": 1.0,\n",
    "#                 \"std\": 0.5,\n",
    "#                 \"sg_mean\": 0.0,\n",
    "#                 \"sg_std\": 0.5,\n",
    "#                 \"n\": 25,\n",
    "#                 \"m\": 25,\n",
    "#                 \"noise_type\": \"multiplicative\",\n",
    "#                 \"device\": device,\n",
    "#             },\n",
    "#         ) for _ in range(bnn_reps)], axis=0)\n",
    "#         # print(f\"score: {score}\")\n",
    "#         result[\"Complexity score\"].append(score)\n",
    "#         result[\"Method\"].append(method)\n",
    "#         result[\"Epoch\"].append(epoch)\n",
    "\n",
    "#     return result\n",
    "\n",
    "def get_complexity_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, bnn_reps=1,\n",
    "                            save_results_to_dataframe=True, disable_warnings=True):\n",
    "    print(\"Generating complexity results\")\n",
    "    \n",
    "    result = {\n",
    "    \"Score\": [],\n",
    "    \"Method\": [],\n",
    "    \"Index\": []\n",
    "    }\n",
    "    \n",
    "    # print(f\"type(x_batch): {type(x_batch)}   x_batch.shape: {x_batch.shape}\")\n",
    "    for image_idx,x in enumerate(x_batch):   \n",
    "        x_batch_tmp = np.expand_dims(x, axis=0)\n",
    "        y_batch_tmp = np.expand_dims(y_batch[image_idx], axis=0)\n",
    "        \n",
    "        for i, (method, attr) in enumerate(explanations.items()):\n",
    "            if method.split(\"_\")[-1]==\"std\":\n",
    "                    # print(f\"skipping method: {method}\")\n",
    "                    continue\n",
    "            a_batch_tmp = np.expand_dims(attr[image_idx], axis=0)\n",
    "            metric_func = quantus.Sparseness(abs=True,\n",
    "                                                normalise=False,\n",
    "                                                aggregate_func=np.mean,\n",
    "                                                return_aggregate=True,\n",
    "                                                disable_warnings=disable_warnings,\n",
    "                                            )\n",
    "            score = np.mean([metric_func(\n",
    "                model=model,\n",
    "                x_batch=x_batch_tmp,\n",
    "                y_batch=y_batch_tmp,\n",
    "                a_batch=a_batch_tmp,\n",
    "                device=device,\n",
    "                explain_func=explainer_wrapper,\n",
    "                explain_func_kwargs={\n",
    "                    \"method\": method,\n",
    "                    \"posterior_mean\": copy.deepcopy(\n",
    "                        model.to(device).state_dict()\n",
    "                    ),\n",
    "                    \"mean\": 1.0,\n",
    "                    \"std\": 0.5,\n",
    "                    \"sg_mean\": 0.0,\n",
    "                    \"sg_std\": 0.5,\n",
    "                    \"n\": 25,\n",
    "                    \"m\": 25,\n",
    "                    \"noise_type\": \"multiplicative\",\n",
    "                    \"device\": device,\n",
    "                },\n",
    "            ) for _ in range(1)], axis=0)\n",
    "            print(f\"score: {score}\")\n",
    "            result[\"Score\"].append(np.mean(score))\n",
    "            result[\"Method\"].append(method)\n",
    "            result[\"Index\"].append(image_idx)\n",
    "            \n",
    "    df = pd.DataFrame(result)\n",
    "    df_grouped = df.copy()\n",
    "\n",
    "    # Group by the ranking.\n",
    "    df_grouped[\"Rank\"] = df_grouped.groupby(['Index'])[\"Score\"].rank(ascending=True)\n",
    "\n",
    "    # Smaller adjustments.\n",
    "    df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "    df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "    df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "    series_avg = df_grouped.groupby(['Method'])[\"Score\"].mean()\n",
    "    \n",
    "    # Reorder the methods for plotting purporses.\n",
    "    df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "    if save_results_to_dataframe:\n",
    "        df.to_csv(os.path.join(output_dir,f\"df_complexity_{epoch}.csv\"))\n",
    "        df_grouped.to_csv(os.path.join(output_dir,f\"df_complexity__grouped_{epoch}.csv\"))\n",
    "        df_view_ordered.to_csv(os.path.join(output_dir,f\"df_complexity__ordered_{epoch}.csv\"))\n",
    "        series_avg.to_frame().to_csv(os.path.join(output_dir,f\"df_complexity__avgs_{epoch}.csv\"))\n",
    "\n",
    "    return df,df_grouped,df_view_ordered\n",
    "\n",
    "def get_randomisation_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, bnn_reps=1, num_classes=2, seeds=[21,42,100],#,1000,5000],\n",
    "                            # sim_funcs={\"difference\": quantus.similarity_func.difference, \"abs_difference\": quantus.similarity_func.abs_difference},\n",
    "                            sim_funcs={\"ssim\": quantus.similarity_func.ssim,},\n",
    "                            save_results_to_dataframe=True, disable_warnings=True, metric=\"RandomLogit\"):\n",
    "    print(\"Generating randomisation results\")\n",
    "    \n",
    "    seeds = seeds\n",
    "    sim_funcs = sim_funcs\n",
    "\n",
    "    result = {\n",
    "        \"Score\": [],\n",
    "        \"Method\": [],\n",
    "        \"Similarity function\": [],\n",
    "        \"Seed\": []\n",
    "    }\n",
    "\n",
    "    for seed in seeds:\n",
    "        for i, (method, attr) in enumerate(explanations.items()):\n",
    "            if method.split(\"_\")[-1]==\"std\":\n",
    "                    # print(f\"skipping method: {method}\")\n",
    "                    continue\n",
    "            for sim, sim_func in sim_funcs.items():\n",
    "                if metric == \"RandomLogit\":\n",
    "                    metric_func = quantus.RandomLogit(\n",
    "                                            num_classes=num_classes,\n",
    "                                            similarity_func=sim_func,\n",
    "                                            seed = seed,\n",
    "                                            abs=True,\n",
    "                                            normalise=True,\n",
    "                                            aggregate_func=np.mean,\n",
    "                                            return_aggregate=True,\n",
    "                                            disable_warnings=disable_warnings,\n",
    "                                        )\n",
    "                # metric_func = quantus.metrics.randomisation.model_parameter_randomisation.ModelParameterRandomisation\n",
    "                 # metric_func = quantus.metrics.randomisation.model_parameter_randomisation.ModelParameterRandomisation\n",
    "                else:\n",
    "                    metric_func = quantus.ModelParameterRandomisation(\n",
    "                        similarity_func = sim_func,\n",
    "                        seed = seed,\n",
    "                        abs = True,\n",
    "                        normalise = True,\n",
    "                        aggregate_func= np.mean,\n",
    "                        return_aggregate= True,\n",
    "                        return_sample_correlation = True,\n",
    "                        disable_warnings=disable_warnings,\n",
    "                    )\n",
    "                # print(f\"metric: {metric}\")\n",
    "                # score = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "                score = np.mean(np.mean([metric_func(\n",
    "                    model=model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=attr,\n",
    "                    device=device,\n",
    "                    explain_func=explainer_wrapper,\n",
    "                    explain_func_kwargs={\n",
    "                        \"method\": method,\n",
    "                        \"posterior_mean\": copy.deepcopy(\n",
    "                           model.to(device).state_dict()\n",
    "                        ),\n",
    "                        \"mean\": 1.0,\n",
    "                        \"std\": 0.5,\n",
    "                        \"sg_mean\": 0.0,\n",
    "                        \"sg_std\": 0.5,\n",
    "                        \"n\": 25,\n",
    "                        \"m\": 25,\n",
    "                        \"noise_type\": \"multiplicative\",\n",
    "                        \"device\": device,\n",
    "                    },\n",
    "                ) for _ in range(1)], axis=0))\n",
    "                print(f\"score: {score}\")\n",
    "                result[\"Score\"].append(score)\n",
    "                result[\"Method\"].append(method)\n",
    "                result[\"Similarity function\"].append(sim)\n",
    "                result[\"Seed\"].append(seed)\n",
    "                \n",
    "    df = pd.DataFrame(result)\n",
    "    df_grouped = df.copy()\n",
    "\n",
    "    # Group by the ranking.\n",
    "    df_grouped[\"Rank\"] = df_grouped.groupby(['Seed', 'Similarity function'])[\"Score\"].rank(ascending=False)\n",
    "\n",
    "    # Smaller adjustments.\n",
    "    df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "    df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "    df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "    series_avg = df_grouped.groupby(['Method'])[\"Score\"].mean()\n",
    "    \n",
    "    # Reorder the methods for plotting purporses.\n",
    "    df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "    if save_results_to_dataframe:\n",
    "        df.to_csv(os.path.join(output_dir,f\"df_randomisation_{epoch}.csv\"))\n",
    "        df_grouped.to_csv(os.path.join(output_dir,f\"df_randomisation__grouped_{epoch}.csv\"))\n",
    "        df_view_ordered.to_csv(os.path.join(output_dir,f\"df_randomisation__ordered_{epoch}.csv\"))\n",
    "        series_avg.to_frame().to_csv(os.path.join(output_dir,f\"df_randomisation__avgs_{epoch}.csv\"))\n",
    "    return df,df_grouped,df_view_ordered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_robustness_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, bnn_reps=1, avg_sensitivity_samples=10, lower_bounds=np.linspace(0.1,0.2,2),\n",
    "                            # sim_funcs={\"difference\": quantus.similarity_func.difference, \"abs_difference\": quantus.similarity_func.abs_difference},\n",
    "                            sim_funcs={\"difference\": quantus.similarity_func.difference},\n",
    "                            save_results_to_dataframe=True, disable_warnings=True, metric=\"AvgSensitivity\"):\n",
    "    print(\"Generating robustness results\")\n",
    "    \n",
    "    lower_bounds = lower_bounds\n",
    "    sim_funcs = sim_funcs\n",
    "\n",
    "    result = {\n",
    "        \"Score\": [],\n",
    "        \"Method\": [],\n",
    "        \"Similarity function\": [],\n",
    "        \"Lower bound\": []\n",
    "    }\n",
    "    scores = []\n",
    "    \n",
    "    for lb in lower_bounds:\n",
    "        for i, (method, attr) in enumerate(explanations.items()):\n",
    "            if method.split(\"_\")[-1]==\"std\":\n",
    "                    #  print(f\"skipping method: {method}\")\n",
    "                    continue\n",
    "            for sim, sim_func in sim_funcs.items():\n",
    "                if metric == \"AvgSensitivity\":\n",
    "                    metric_func = quantus.AvgSensitivity(nr_samples=avg_sensitivity_samples,\n",
    "                                                    lower_bound=lb,\n",
    "                                                    norm_numerator=quantus.norm_func.fro_norm,\n",
    "                                                    norm_denominator=quantus.norm_func.fro_norm,\n",
    "                                                    perturb_func=quantus.perturb_func.uniform_noise,\n",
    "                                                    similarity_func=sim_func,\n",
    "                                                    abs=False,\n",
    "                                                    normalise=False,\n",
    "                                                    aggregate_func=np.mean,\n",
    "                                                    return_aggregate=True,\n",
    "                                                    disable_warnings=disable_warnings,\n",
    "                                                )\n",
    "                else:\n",
    "                    metric_func = quantus.LocalLipschitzEstimate(nr_samples=5,\n",
    "                                        perturb_std=0.1,\n",
    "                                        perturb_mean=0.0,\n",
    "                                        norm_numerator=quantus.norm_func.fro_norm,\n",
    "                                        norm_denominator=quantus.norm_func.fro_norm,\n",
    "                                        perturb_func=quantus.perturb_func.uniform_noise,\n",
    "                                        # similarity_func=quantus.similarity_func.difference,\n",
    "                                        abs=False,\n",
    "                                        normalise=False,\n",
    "                                        aggregate_func=np.mean,\n",
    "                                        return_aggregate=True,\n",
    "                                        disable_warnings=True\n",
    "                                        )\n",
    "                # print(f\"metric: {metric}\")\n",
    "                # score = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "                score = np.mean([metric_func(\n",
    "                    model=model,\n",
    "                    x_batch=x_batch,\n",
    "                    y_batch=y_batch,\n",
    "                    a_batch=attr,\n",
    "                    device=device,\n",
    "                    explain_func=explainer_wrapper,\n",
    "                    explain_func_kwargs={\n",
    "                        \"method\": method,\n",
    "                        \"posterior_mean\": copy.deepcopy(\n",
    "                            model.to(device).state_dict()\n",
    "                        ),\n",
    "                        \"mean\": 1.0,\n",
    "                        \"std\": 0.5,\n",
    "                        \"sg_mean\": 0.0,\n",
    "                        \"sg_std\": 0.5,\n",
    "                        \"n\": 25,\n",
    "                        \"m\": 25,\n",
    "                        \"noise_type\": \"multiplicative\",\n",
    "                        \"device\": device,\n",
    "                    },\n",
    "                ) for _ in range(1)], axis=0)\n",
    "                print(f\"score: {score}\")\n",
    "                score = np.mean(score)\n",
    "                print(f\"score2: {score}\")\n",
    "                result[\"Score\"].append(score)\n",
    "                result[\"Method\"].append(method)\n",
    "                result[\"Similarity function\"].append(sim)\n",
    "                result[\"Lower bound\"].append(lb)\n",
    "                \n",
    "    df = pd.DataFrame(result)\n",
    "    df_grouped = df.copy()\n",
    "\n",
    "    # Group by the ranking.\n",
    "    df_grouped[\"Rank\"] = df_grouped.groupby(['Lower bound', 'Similarity function'])[\"Score\"].rank()\n",
    "\n",
    "    # Smaller adjustments.\n",
    "    df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "    df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "    df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "    series_avg = df_grouped.groupby(['Method'])[\"Score\"].mean()\n",
    "\n",
    "    # Reorder the methods for plotting purporses.\n",
    "    df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "    if save_results_to_dataframe:\n",
    "        df.to_csv(os.path.join(output_dir,f\"df_robustness_{epoch}.csv\"))\n",
    "        df_grouped.to_csv(os.path.join(output_dir,f\"df_robustness__grouped_{epoch}.csv\"))\n",
    "        df_view_ordered.to_csv(os.path.join(output_dir,f\"df_robustness__ordered_{epoch}.csv\"))\n",
    "        series_avg.to_frame().to_csv(os.path.join(output_dir,f\"df_robustness__avgs_{epoch}.csv\"))\n",
    "\n",
    "    return df,df_grouped,df_view_ordered\n",
    "    \n",
    "    \n",
    "# def get_sensitivity_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, baseline_strategies=[\"mean\", \"uniform\"], \n",
    "#                             subset_sizes=np.array([7,14,28]), \n",
    "#                             sim_funcs={\"pearson\": quantus.similarity_func.correlation_pearson, \"spearman\": quantus.similarity_func.correlation_spearman},\n",
    "#                             save_results_to_dataframe=True):\n",
    "    \n",
    "#     baseline_strategies = baseline_strategies\n",
    "#     subset_sizes = subset_sizes\n",
    "#     sim_funcs = sim_funcs\n",
    "\n",
    "#     result = {\n",
    "#         \"Faithfulness score\": [],\n",
    "#         \"Method\": [],\n",
    "#         \"Similarity function\": [],\n",
    "#         \"Baseline strategy\": [],\n",
    "#         \"Subset size\": [],\n",
    "#     }\n",
    "\n",
    "\n",
    "#     for i, (method, attr) in enumerate(explanations.items()):\n",
    "#         if i % 2 != 0:\n",
    "#             # print(\"skipping method: {method}\")\n",
    "#             continue\n",
    "#         metric = quantus.FaithfulnessCorrelation(abs=True,\n",
    "#                                                 normalise=True,\n",
    "#                                                 return_aggregate=True,\n",
    "#                                                 disable_warnings=True,\n",
    "#                                                 aggregate_func=np.mean,\n",
    "#                                                 normalise_func=quantus.normalise_func.normalise_by_negative,\n",
    "#                                                 nr_runs=10,\n",
    "#                                                 perturb_baseline=\"mean\",\n",
    "#                                                 perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "#                                                 similarity_func=quantus.similarity_func.correlation_pearson,\n",
    "#                                                 subset_size=7)\n",
    "        \n",
    "#         # print(f\"metric: {metric}\")\n",
    "#         score = metric(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "#         result[\"Method\"].append(method)\n",
    "#         result[\"Faithfulness score\"].append(score[0])\n",
    "#         result[\"Similarity function\"].append(\"pearson\")\n",
    "\n",
    "    # df = pd.DataFrame(result)\n",
    "    # df_grouped = df.copy()\n",
    "\n",
    "    # # Group by the ranking.\n",
    "    # df_grouped[\"Rank\"] = df_grouped.groupby(['Baseline strategy', 'Subset size', 'Similarity function'])[\"Faithfulness score\"].rank()\n",
    "\n",
    "    # # Smaller adjustments.\n",
    "    # df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "    # df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "    # df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "\n",
    "    # # Reorder the methods for plotting purporses.\n",
    "    # df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "    # df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "    # df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "    # df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "    # # df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "    # if save_results_to_dataframe:\n",
    "    #     df.to_csv(os.path.join(output_dir,f\"df_sensitivity_{epoch}.csv\"))\n",
    "    #     df_grouped.to_csv(os.path.join(output_dir,f\"df_sensitivity_grouped_{epoch}.csv\"))\n",
    "    #     df_view_ordered.to_csv(os.path.join(output_dir,f\"df_sensitivity_ordered_{epoch}.csv\"))\n",
    "\n",
    "    # return df,df_grouped,df_view_ordered\n",
    "\n",
    "\n",
    "\n",
    "def get_faithfulness_results(model, x_batch, y_batch, explanations, device, output_dir, epoch, bnn_reps=1, baseline_strategies=[\"mean\",\"uniform\"], \n",
    "                            subset_sizes=np.array([3,7,12,18,22]), \n",
    "                            sim_funcs={\"pearson\": quantus.similarity_func.correlation_pearson, \"spearman\": quantus.similarity_func.correlation_spearman},\n",
    "                            save_results_to_dataframe=True, metric=\"fc\"):\n",
    "    print(\"Generating faithfulness results\")\n",
    "    \n",
    "    baseline_strategies = baseline_strategies\n",
    "    subset_sizes = subset_sizes\n",
    "    sim_funcs = sim_funcs\n",
    "\n",
    "    result = {\n",
    "        \"Score\": [],\n",
    "        \"Method\": [],\n",
    "        \"Similarity function\": [],\n",
    "        \"Baseline strategy\": [],\n",
    "        \"Subset size\": [],\n",
    "    }\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    for b in baseline_strategies:\n",
    "        for s in subset_sizes:\n",
    "            for i, (method, attr) in enumerate(explanations.items()):\n",
    "                # if i % 2 != 0:\n",
    "                if method.split(\"_\")[-1]==\"std\":\n",
    "                    # print(f\"skipping method: {method}\")\n",
    "                    continue\n",
    "                for sim, sim_func in sim_funcs.items():\n",
    "                    print(f\"bl: {b}   s: {s}\")\n",
    "                    if metric.lower() == \"road\":\n",
    "                        metric_func = quantus.ROAD(abs=True,\n",
    "                                            normalise=True,\n",
    "                                            return_aggregate=True,\n",
    "                                            disable_warnings=True,\n",
    "                                            aggregate_func=np.mean,\n",
    "                                            normalise_func=quantus.normalise_func.normalise_by_negative,\n",
    "                                            perturb_baseline=b,)\n",
    "                        \n",
    "                        # print(f\"metric: {metric}\")\n",
    "                        score = metric_func(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "                        # print(f\"score: {score}\")\n",
    "                        result[\"Method\"].append(method)\n",
    "                        result[\"Baseline strategy\"].append(b.capitalize())\n",
    "                        result[\"Subset size\"].append(s)\n",
    "                        result[\"Score\"].append(score)\n",
    "                        result[\"Similarity function\"].append(sim)\n",
    "                    else:\n",
    "                        metric_func = quantus.FaithfulnessCorrelation(abs=True,\n",
    "                                                                normalise=True,\n",
    "                                                                return_aggregate=True,\n",
    "                                                                disable_warnings=True,\n",
    "                                                                aggregate_func=np.mean,\n",
    "                                                                normalise_func=quantus.normalise_func.normalise_by_negative,\n",
    "                                                                nr_runs=10,\n",
    "                                                                perturb_baseline=b,\n",
    "                                                                perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "                                                                similarity_func=sim_func,\n",
    "                                                                subset_size=s)\n",
    "                    \n",
    "                        # print(f\"metric: {metric}\")\n",
    "                        score = metric_func(model=model, x_batch=x_batch, y_batch=y_batch, a_batch=attr, device=device)\n",
    "                        # print(f\"score: {score}\")\n",
    "                        result[\"Method\"].append(method)\n",
    "                        result[\"Baseline strategy\"].append(b.capitalize())\n",
    "                        result[\"Subset size\"].append(s)\n",
    "                        result[\"Score\"].append(score[0])\n",
    "                        result[\"Similarity function\"].append(sim)\n",
    "\n",
    "    return result\n",
    "\n",
    "    df = pd.DataFrame(result)\n",
    "    df_grouped = df.copy()\n",
    "\n",
    "    # Group by the ranking.\n",
    "    df_grouped[\"Rank\"] = df_grouped.groupby(['Baseline strategy', 'Subset size', 'Similarity function'])[\"Score\"].rank()\n",
    "\n",
    "    # Smaller adjustments.\n",
    "    df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "    df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "    df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "    series_avg = df_grouped.groupby(['Method'])[\"Score\"].mean()\n",
    "\n",
    "    # Reorder the methods for plotting purporses.\n",
    "    df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "    df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "    if save_results_to_dataframe:\n",
    "        df.to_csv(os.path.join(output_dir,f\"df_faithfulness_{epoch}.csv\"))\n",
    "        df_grouped.to_csv(os.path.join(output_dir,f\"df_faithfulness_grouped_{epoch}.csv\"))\n",
    "        df_view_ordered.to_csv(os.path.join(output_dir,f\"df_faithfulness_ordered_{epoch}.csv\"))\n",
    "        series_avg.to_frame().to_csv(os.path.join(output_dir,f\"df_faithfulness_avgs_{epoch}.csv\"))\n",
    "\n",
    "    return df,df_grouped,df_view_ordered\n",
    "\n",
    "\n",
    "# def create_complexity_dfs(result,output_dir,save_results_to_dataframe=True):\n",
    "#     df = pd.DataFrame(result)\n",
    "#     df_grouped = df.copy()\n",
    "\n",
    "#     # Group by the ranking.\n",
    "#     df_grouped[\"Rank\"] = df_grouped.groupby(['Epoch'])[\"Complexity score\"].rank(ascending=False)\n",
    "\n",
    "#     # Smaller adjustments.\n",
    "#     df_grouped = df_grouped.loc[:, ~df_grouped.columns.str.contains('^Unnamed')]\n",
    "#     df_grouped.columns = map(lambda x: str(x).capitalize(), df_grouped.columns)\n",
    "\n",
    "#     df_view = df_grouped.groupby([\"Method\"])[\"Rank\"].value_counts(normalize=True).mul(100).reset_index(name='Percentage').round(2)\n",
    "\n",
    "#     # Reorder the methods for plotting purporses.\n",
    "#     df_view_ordered = pd.DataFrame(columns=[\"Method\", \"Rank\", \"Percentage\"])\n",
    "#     df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'Saliency']], ignore_index=True)\n",
    "#     df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'GradientShap']], ignore_index=True)\n",
    "#     df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'IntegratedGradients']], ignore_index=True)\n",
    "#     # df_view_ordered = df_view_ordered.append([df_view.loc[df_view[\"Method\"] == 'FusionGrad']], ignore_index=True)\n",
    "\n",
    "#     if save_results_to_dataframe:\n",
    "#         df.to_csv(os.path.join(output_dir,f\"df_complexity.csv\"))\n",
    "#         df_grouped.to_csv(os.path.join(output_dir,f\"df_complexity__grouped.csv\"))\n",
    "#         df_view_ordered.to_csv(os.path.join(output_dir,f\"df_complexity__ordered.csv\"))\n",
    "    \n",
    "#     return df, df_grouped, df_view_ordered\n",
    "\n",
    "\n",
    "def plot_ranking_results(df_view_ordered,output_dir,epoch,metric_name):\n",
    "        \n",
    "    plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{metric_name}.jpg\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6.5,5))\n",
    "    ax = sns.histplot(x='Method', hue='Rank', weights='Percentage', multiple='stack', data=df_view_ordered, shrink=0.6, palette=\"colorblind\", legend=False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.set_ylabel('Frequency of rank', fontsize=15)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels([\"SAL\", \"GS\", \"IG\", \"FG\"])\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=2, fancybox=True, shadow=False, labels=['1st', \"2nd\", \"3rd\", \"4th\"][::-1])\n",
    "    # plt.axvline(x=3.5, ymax=0.95, color='black', linestyle='-')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_loc)\n",
    "    plt.close(\"all\")\n",
    "        \n",
    "def multi_plot_ranking_results(df_views_ordered,output_dir,epoch,metric_names):\n",
    "    # df_views_ordered_loc = df_views_ordered.copy()\n",
    "    # print(f\"before len(df_views_ordered_loc): {len(df_views_ordered_loc)}\")\n",
    "    # if not complexity_result is None:\n",
    "    #     print(f\"not none\")\n",
    "    #     df_views_ordered_loc.append(create_complexity_dfs(complexity_result, output_dir)[2])\n",
    "        \n",
    "    plot_loc = os.path.join(output_dir,f\"prob_{epoch}_all_metrics.jpg\")\n",
    "    \n",
    "    # print(f\"after len(df_views_ordered_loc): {len(df_views_ordered_loc)}\")\n",
    "    \n",
    "    for m in metric_names:\n",
    "        print(f\"m: {m}\")\n",
    "    # fig, ax = plt.subplots(figsize=(6.5,5))\n",
    "    fig, axes = plt.subplots(ncols=int(len(df_views_ordered)), figsize=(14, 6))\n",
    "    # fig.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fancybox=True, shadow=False, labels=['1st', \"2nd\", \"3rd\"][::-1])\n",
    "    fig.suptitle(\"Ranking of XAI functions on different metrics\")\n",
    "    for i,df_view_ordered in enumerate(df_views_ordered):\n",
    "        # print(f\"{metric_names[i]}\")\n",
    "        sns.histplot(ax=axes[i], x='Method', hue='Rank', weights='Percentage', multiple='stack', data=df_view_ordered, shrink=0.6, palette=\"colorblind\", legend=False)\n",
    "        axes[i].spines[\"right\"].set_visible(False)\n",
    "        axes[i].spines['top'].set_visible(False)\n",
    "        axes[i].tick_params(axis='both', which='major', labelsize=16)\n",
    "        axes[i].set_ylabel('Frequency of rank', fontsize=15)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_xticklabels([\"SAL\", \"GS\", \"IG\", \"FG\"])\n",
    "        axes[i].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fancybox=True, shadow=False, labels=['1st', \"2nd\", \"3rd\", \"4th\"][::-1])\n",
    "        axes[i].set_title(f\"{metric_names[i]}\")\n",
    "        # axes[i].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fancybox=True, shadow=False, labels=['1st', \"2nd\", \"3rd\"][::-1])\n",
    "        # axes[i].axvline(x=3, ymax=0.95, color='black', linestyle='-')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_loc)\n",
    "    plt.close(\"all\")        \n",
    "        \n",
    "        \n",
    "    # for idx,x in enumerate(x_batch):\n",
    "    #     if model_type == \"BNN\":\n",
    "    #         fig, axes = plt.subplots(nrows=1, ncols=2+len(explanations), figsize=(12, 4)) #, gridspec_kw={'height_ratios': [12 if i != 1 else 4 for i in range(2+len(explanations))]})\n",
    "    #     else:\n",
    "    #         fig, axes = plt.subplots(nrows=1, ncols=1+int(len(explanations)/2), figsize=(6, 4))\n",
    "\n",
    "    #     if model_type == \"BNN\":\n",
    "    #         fig.suptitle(\"Explanations for BNN\", fontsize=16)\n",
    "    #     else:\n",
    "    #         fig.suptitle(\"Explanations for LeNet\", fontsize=16)\n",
    "\n",
    "    #     # axes[0].imshow(np.moveaxis(quantus.normalise_func.denormalise(x_batch[index].cpu().numpy(), mean=np.array([0.485, 0.456, 0.406]), std=np.array([0.229, 0.224, 0.225])), 0, -1), vmin=0.0, vmax=1.0)\n",
    "    #     # img\n",
    "    #     #axes[0].imshow(cv2.resize(np.moveaxis(x, 0, -1), (12,12)).astype(np.uint8), vmin=0.0, vmax=1.0)\n",
    "    #     #  cv2.resize(np.moveaxis(x_batch[0], 0, -1), (20,20))\n",
    "    #     axes[0].imshow(np.moveaxis(x, 0, -1), vmin=0.0, vmax=1.0)\n",
    "    #     axes[0].title.set_text(f\"class {y_batch[idx].item()}\")\n",
    "    #     axes[0].axis(\"off\")\n",
    "    #     # probability bar\n",
    "    #     if model_type == \"BNN\":\n",
    "    #         axes[1].bar(np.arange(num_classes), np.array([probabilities[idx][0],probabilities[idx][1]]), color='red')\n",
    "    #         axes[1].set_xticks(np.arange(num_classes))\n",
    "    #         axes[1].set_ylim([0, 1])\n",
    "    #         axes[1].set_title(f\"{num_forward_passes} draws\")\n",
    "    #         # sns.barplot(np.arange(num_classes),np.array([probabilities[idx][0],probabilities[idx][1]]), ax=axes[1])\n",
    "    #         i = 2\n",
    "    #     else:\n",
    "    #         i = 1\n",
    "\n",
    "    #     for j, (k, v) in enumerate(explanations.items()):\n",
    "    #         # skip std plots for lenet (fixed weights)\n",
    "    #         if model_type != \"BNN\" and j % 2 != 0:\n",
    "    #             continue\n",
    "    #         explanation = explanations[k][idx].reshape(28, 28)\n",
    "            \n",
    "    #         csums = np.sum(explanation, 0)\n",
    "    #         rsums = np.sum(explanation, 1)\n",
    "\n",
    "    #         axes[i].imshow(quantus.normalise_func.normalise_by_negative(explanation), cmap=\"seismic\", vmin=-1.0, vmax=1.0)\n",
    "    #         axes[i].plot(-abs(csums), color='blue') #, marker='o') #, mfc='orange')\n",
    "    #         axes[i].plot(-abs(rsums), y_indices_rowsums, color='blue') #, marker='o')#, mfc='orange')\n",
    "    #         # axes[i].plot(csums, color='blue') #, marker='o') #, mfc='orange')\n",
    "    #         # axes[i].plot(rsums, y_indices_rowsums, color='blue') #, marker='o')#, mfc='orange')\n",
    "    #         axes[i].title.set_text(f\"{k}\")\n",
    "    #         axes[i].axis(\"off\")\n",
    "    #         i += 1\n",
    "\n",
    "    #     plot_loc = os.path.join(output_dir,f\"prob_{epoch}_{idx}_explanation.jpg\")\n",
    "    #     plt.savefig(plot_loc)\n",
    "    #     plt.close('all')\n",
    "        \n",
    "\n",
    "# def plot_sensitivity_results(df_view_ordered,output_dir,epoch):\n",
    "#     plot_loc = os.path.join(output_dir,f\"prob_{epoch}_sensitivity.jpg\")\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(6.5,5))\n",
    "#     ax = sns.histplot(x='Method', hue='Rank', weights='Percentage', multiple='stack', data=df_view_ordered, shrink=0.6, palette=\"colorblind\", legend=False)\n",
    "#     ax.spines[\"right\"].set_visible(False)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "#     ax.set_ylabel('Frequency of rank', fontsize=15)\n",
    "#     ax.set_xlabel('')\n",
    "#     ax.set_xticklabels([\"SAL\", \"GS\", \"IG\"])\n",
    "#     plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.1), ncol=3, fancybox=True, shadow=False, labels=['1st', \"2nd\", \"3rd\"][::-1])\n",
    "#     plt.axvline(x=3.5, ymax=0.95, color='black', linestyle='-')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(plot_loc)\n",
    "#     plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_plot_ranking_results(df_views_ordered,bnn_probs_out_path,i,metric_names,complexity_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(filename:str = \"config_vae_inference_local.cfg\"):\n",
    "    global NUM_CLASSES, TEST_IMGS_ROOT_DIR, OUTPUT_DIR, MODEL_TYPE \n",
    "    global BATCH_SIZE, CHECKPOINT_LOC_CLASSIFICIATION_MODEL, NUM_BNN_FORWARD_PASSES, CLASSIFIER_INPUT_DIMS\n",
    "    global CUDA_GPU_INDEX, NORMALIZE\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(filename)\n",
    "\n",
    "    NUM_CLASSES = int(config[\"DEFAULT\"][\"NUM_CLASSES\"])\n",
    "\n",
    "    TEST_IMGS_ROOT_DIR = os.path.join(config[\"DEFAULT\"][\"TEST_DIR_IMGS\"])\n",
    "    OUTPUT_DIR = os.path.join(config[\"DEFAULT\"][\"OUTPUT_DIR\"])\n",
    "\n",
    "    CHECKPOINT_LOC_CLASSIFICIATION_MODEL = os.path.join(config[\"DEFAULT\"][\"CHECKPOINT_LOC_CLASSIFICIATION_MODEL\"])\n",
    "    \n",
    "    l = list(map(str.lower, CHECKPOINT_LOC_CLASSIFICIATION_MODEL.split(\"/\")))\n",
    "    \n",
    "    if \"bnn\" in l:\n",
    "        MODEL_TYPE = \"BNN\"\n",
    "    elif \"lenet\" in l:\n",
    "        MODEL_TYPE  = \"LeNet\"\n",
    "    else:\n",
    "        print(\"model type has to be set via correct path (path has either to contain 'lenet' or 'bnn'). Exiting...\")\n",
    "        sys.exit()\n",
    "\n",
    "    NUM_BNN_FORWARD_PASSES = int(config[\"DEFAULT\"][\"NUM_BNN_FORWARD_PASSES\"])\n",
    "    CLASSIFIER_INPUT_DIMS = int(config[\"DEFAULT\"][\"CLASSIFIER_INPUT_DIMS\"])\n",
    "    BATCH_SIZE = int(config[\"DEFAULT\"][\"BATCH_SIZE\"])\n",
    "    \n",
    "    CUDA_GPU_INDEX = int(config[\"CUDA\"][\"CUDA_GPU_INDEX\"])\n",
    "    NORMALIZE = bool(int(config[\"DEFAULT\"][\"NORMALIZE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting results\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m sec_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPredicting results\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m probs, plot_list \u001b[39m=\u001b[39m get_bnn_probabilities(x_batch, class_model, device, NUM_BNN_FORWARD_PASSES)\n\u001b[1;32m     54\u001b[0m \u001b[39m# print(f\"probs: {probs}\")\u001b[39;00m\n\u001b[1;32m     55\u001b[0m time_dict[\u001b[39m\"\u001b[39m\u001b[39mbnn_probs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m sec_time\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mget_bnn_probabilities\u001b[0;34m(image_tensor, class_model, device, num_forward_passes)\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_unsqueezed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(tensor,\u001b[39m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     preds \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margmax(class_model(tensor_unsqueezed)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_forward_passes)]\n\u001b[1;32m     10\u001b[0m mxt_prob \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(preds)\n\u001b[1;32m     11\u001b[0m dot_prob \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m mxt_prob\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_unsqueezed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(tensor,\u001b[39m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     preds \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39margmax(class_model(tensor_unsqueezed)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_forward_passes)]\n\u001b[1;32m     10\u001b[0m mxt_prob \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(preds)\n\u001b[1;32m     11\u001b[0m dot_prob \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m mxt_prob\n",
      "File \u001b[0;32m~/anaconda3/envs/blitz/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/dan/1407183E63647361/FH/XAI/scripts/quantus/bayesian_models.py:40\u001b[0m, in \u001b[0;36mBayesianModel3BatchNormActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# x = F.batch_norm(x,self.running_mu1,self.running_std1,training=True)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m---> 40\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[1;32m     41\u001b[0m \u001b[39m#print(\"after conv2: {}\".format(x.size()))\u001b[39;00m\n\u001b[1;32m     42\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/blitz/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/blitz/lib/python3.9/site-packages/blitz/modules/conv_bayesian_layer.py:232\u001b[0m, in \u001b[0;36mBayesianConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreeze:\n\u001b[1;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_frozen(x)\n\u001b[0;32m--> 232\u001b[0m w \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_sampler\u001b[39m.\u001b[39;49msample()\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias:\n\u001b[1;32m    235\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_sampler\u001b[39m.\u001b[39msample()\n",
      "File \u001b[0;32m~/anaconda3/envs/blitz/lib/python3.9/site-packages/blitz/modules/weight_sampler.py:31\u001b[0m, in \u001b[0;36mTrainableRandomDistribution.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     21\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m    Samples weights by sampling form a Normal distribution, multiplying by a sigma, which is \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m    a function from a trainable parameter, and adding a mean\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m        torch.tensor with same shape as self.mu and self.rho\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps_w\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mnormal_()\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog1p(torch\u001b[39m.\u001b[39mexp(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrho))\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmu \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigma \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps_w\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parse_config(\"config_vae_inference_local.cfg\")\n",
    "\n",
    "if not os.path.exists(os.path.join(CHECKPOINT_LOC_CLASSIFICIATION_MODEL)):\n",
    "   sys.exit(\"no valid CHECKPOINT_LOC_CLASSIFICIATION_MODEL path\") \n",
    "\n",
    "device = torch.device(f\"cuda:{CUDA_GPU_INDEX}\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "if MODEL_TYPE == \"BNN\":\n",
    "    class_model = bayesian_models.BayesianModel3BatchNormActivation(CLASSIFIER_INPUT_DIMS,NUM_CLASSES)\n",
    "else:\n",
    "    class_model = bayesian_models.LeNet(CLASSIFIER_INPUT_DIMS,NUM_CLASSES)\n",
    "    NUM_BNN_FORWARD_PASSES = 1\n",
    "    # print(f\"NUM_BNN_FPASSES: {NUM_BNN_FORWARD_PASSES}\")\n",
    "\n",
    "class_model.load_state_dict(torch.load(CHECKPOINT_LOC_CLASSIFICIATION_MODEL,map_location=torch.device('cpu')))\n",
    "class_model.eval()\n",
    "\n",
    "# bnn_reps = config.NUM_BNN_FORWARD_PASSES\n",
    "\n",
    "ds = Custom_Dataset(TEST_IMGS_ROOT_DIR, device, NORMALIZE)\n",
    "dl = DataLoader(ds,batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "vae_out_path = os.path.join(os.path.join(OUTPUT_DIR),\"vae\")\n",
    "bnn_probs_out_path = os.path.join(os.path.join(OUTPUT_DIR),\"bnn\")\n",
    "df_out_path = os.path.join(bnn_probs_out_path,\"dfs\")\n",
    "# df_out_path = os.path.join(OUTPUT_DIR)\n",
    "\n",
    "vae_utils.make_folders(os.path.join(OUTPUT_DIR), \"bnn\", \"vae\", os.path.join(\"bnn/dfs\"))\n",
    "\n",
    "# complexity_result = {\n",
    "#     \"Complexity score\": [],\n",
    "#     \"Method\": [],\n",
    "#     \"Epoch\": []\n",
    "# }\n",
    "\n",
    "\n",
    "# metric_names = [\"Faithfulness\", \"Robustness\", \"Randomisation\", \"Complexity\"]\n",
    "# metric_names = [\"Faithfulness\", \"Randomisation\", \"Complexity\"]\n",
    "\n",
    "for i, ([x_batch,x_batch_plot],l) in enumerate(dl):\n",
    "    # if i == 0:\n",
    "    #     continue\n",
    "    if i > 0:\n",
    "        break\n",
    "    \n",
    "    df_views_ordered = []\n",
    "    time_dict = {}\n",
    "    start_time = time.time()\n",
    "\n",
    "    sec_time = time.time()\n",
    "    print(\"Predicting results\")\n",
    "    probs, plot_list = get_bnn_probabilities(x_batch, class_model, device, NUM_BNN_FORWARD_PASSES)\n",
    "    # print(f\"probs: {probs}\")\n",
    "    time_dict[\"bnn_probs\"] = time.time() - sec_time\n",
    "    print(f\"time for predictions: {time.time()-sec_time}\")\n",
    "    \n",
    "    x_batch = x_batch.to(device)\n",
    "    x_batch.requires_grad = True\n",
    "    y_batch = torch.from_numpy(np.array(np.argmax(probs,axis=1),dtype=np.int64)).to(device)\n",
    "\n",
    "    # vae_utils.save_tensor_to_image_known_path(x_batch,NUM_SAMPLES,i,vae_out_path)\n",
    "    sec_time = time.time()\n",
    "    print(\"Generating XAI explanations\")\n",
    "    explanations = get_xai_explanations(x_batch, y_batch, class_model, device, MODEL_TYPE, NUM_BNN_FORWARD_PASSES)\n",
    "    time_dict[\"explanations\"] = time.time() - sec_time\n",
    "    print(f\"time for explanations generation: {time.time()-sec_time}\")\n",
    "\n",
    "    x_batch, x_batch_plot, y_batch = x_batch.detach().cpu().numpy(), x_batch_plot.detach().cpu().numpy(), y_batch.detach().cpu().numpy()\n",
    "    # # plot_explanations(x_batch.detach(), y_batch.detach(), explanations, probs, config.NUM_CLASSES, bnn_probs_out_path, i)\n",
    "    plot_explanations_with_sums(x_batch_plot, y_batch, explanations, probs, NUM_CLASSES, bnn_probs_out_path, i, NUM_BNN_FORWARD_PASSES, MODEL_TYPE)\n",
    "    \n",
    "    # xai_methods, xai_metrics = get_xai_methods_and_metrics(explanations, NUM_CLASSES)\n",
    "    # # # res = get_xai_quantification_results(x_batch, y_batch, class_model, device, xai_methods, xai_metrics, NUM_BNN_FORWARD_PASSES)\n",
    "    # # # df, df_normalised_rank = xai_results_postprocess(xai_methods, xai_metrics, res, bnn_probs_out_path, i)\n",
    "    # # df, df_grouped, df_view_ordered = get_sensitivity_results(class_model, x_batch, y_batch, explanations, device, bnn_probs_out_path, i, baseline_strategies=[\"mean\",\"uniform\",\"black\",\"white\"])\n",
    "    # # # plot_ranking_results(df_view_ordered,bnn_probs_out_path,i,\"faithfulness\")\n",
    "    # # df, df_grouped, df_view_ordered = get_robustness_results(class_model, x_batch, y_batch, explanations, device, bnn_probs_out_path, i)\n",
    "    # # # # df, df_grouped, df_view_ordered = get_randomisation_results(class_model, x_batch, y_batch, explanations, device, bnn_probs_out_path, i)\n",
    "        # # plot_ranking_results(df_view_ordered,bnn_probs_out_path,i,\"faithfulness\")\n",
    "\n",
    "    # df_views_ordered.append(get_sensitivity_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES, baseline_strategies=[\"mean\",\"uniform\",\"black\",\"white\"])[2])\n",
    "\n",
    "    # df_views_ordered.append(get_robustness_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES)[2])\n",
    "    # df_views_ordered.append(get_randomisation_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES)[2])\n",
    "    # # complexity_result = get_complexity_results(class_model, x_batch, y_batch, explanations, device, bnn_probs_out_path, i, complexity_result)\n",
    "    # df_views_ordered.append(get_complexity_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES)[2])\n",
    "    # plot_ranking_results(df_views_ordered[-1],bnn_probs_out_path,i,\"randomisation\")#,complexity_result=complexity_result)\n",
    "    \n",
    "    # methods = {\"Faithfulness\": get_faithfulness_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES, metric=\"road\"),\n",
    "    #            \"Robustness\": get_robustness_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES)}#,#, metric=\"bla\"), not for both (fro_norm)\n",
    "    #         #    \"Randomisation\": get_randomisation_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES),#, metric=\"bla\"), not for bnn (deepcopy)\n",
    "    #         #    \"Complexity\": get_complexity_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES)}\n",
    "    \n",
    "    # print(\"Starting evaluation process...\")\n",
    "    \n",
    "    # res = get_faithfulness_results(class_model, x_batch, y_batch, explanations, device, df_out_path, i, bnn_reps = NUM_BNN_FORWARD_PASSES, metric=\"road\")\n",
    "    \n",
    "    # for method, fct in methods.items():\n",
    "    #     method_time = time.time()\n",
    "    #     df, df_grouped, df_view_ordered = fct\n",
    "    #     df_views_ordered.append(df_view_ordered)\n",
    "    #     plot_ranking_results(df_views_ordered[-1],bnn_probs_out_path,i,method)\n",
    "    #     print(f\"time for {method.lower()} result generation: {time.time()-method_time}\")\n",
    "    #     time_dict[method] = time.time()-method_time\n",
    "    \n",
    "    # time_dict[\"all\"] = time.time()-start_time\n",
    "    # print(f\"time for all metrics: {time_dict['all']}\")\n",
    "    # pd.DataFrame(pd.Series(time_dict,name=\"time\")).to_csv(os.path.join(df_out_path,f\"df_times_{i}.csv\"))\n",
    "    \n",
    "    # multi_plot_ranking_results(df_views_ordered, bnn_probs_out_path, i, list(methods.keys()))\n",
    "    \n",
    "    # # multi_plot_ranking_results(df_views_ordered, bnn_probs_out_path, i, [k.title() for k in time_dict.keys() if k != \"all\"])\n",
    "    \n",
    "    # print(f\"batch {i} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time for randomisation result generation: 0.1786808967590332\n",
    "# time for complexity result generation: 0.16939043998718262\n",
    "# time for all metrics: 0.3481442928314209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.17624553, -0.9960372 ,  0.0209351 , ...,  0.24069881,\n",
       "          0.32969385, -0.02676467],\n",
       "        [-1.5382316 ,  0.75300705, -2.7950165 , ..., -0.1263105 ,\n",
       "         -0.10576378, -1.0180641 ],\n",
       "        [ 0.18729898, -1.7753942 ,  0.443183  , ...,  0.7980205 ,\n",
       "         -0.23002842, -0.44936904],\n",
       "        ...,\n",
       "        [-0.38557163,  0.30142114,  0.0569355 , ..., -1.6081734 ,\n",
       "          0.2721547 , -0.16181341],\n",
       "        [-0.22954102,  0.54201096,  0.09387596, ...,  0.02369696,\n",
       "         -0.26130134,  0.0616801 ],\n",
       "        [-0.14371544, -0.17132768, -0.04146149, ..., -0.17579845,\n",
       "         -0.32051405,  0.22982499]],\n",
       "\n",
       "       [[ 0.2774817 ,  0.39340746, -0.7173558 , ..., -0.01491425,\n",
       "          0.19197494, -0.28781974],\n",
       "        [-0.03366408, -0.5304768 ,  1.0151659 , ...,  1.0315105 ,\n",
       "          1.101684  ,  0.6832551 ],\n",
       "        [ 0.5846871 ,  0.20212722, -0.4523396 , ...,  0.26995775,\n",
       "          1.262933  ,  0.66842467],\n",
       "        ...,\n",
       "        [ 0.5710393 , -0.27555895,  1.5714474 , ..., -0.6010056 ,\n",
       "          0.7513909 ,  0.5087476 ],\n",
       "        [-0.2987916 ,  1.8981221 , -0.5024451 , ..., -0.56745005,\n",
       "         -1.8049622 ,  0.11045418],\n",
       "        [-0.03018473, -0.06522099,  0.138532  , ..., -0.06663038,\n",
       "          0.46429873,  0.12114283]],\n",
       "\n",
       "       [[ 0.14224316,  0.26005417, -0.7349589 , ...,  0.26108614,\n",
       "          0.3241853 , -0.17972903],\n",
       "        [ 0.9583505 ,  0.6138642 ,  1.1993649 , ...,  1.3041748 ,\n",
       "          0.6204163 ,  1.2025785 ],\n",
       "        [ 0.52710795,  0.63206434,  0.65511435, ...,  0.0958072 ,\n",
       "          1.6938671 ,  0.45530242],\n",
       "        ...,\n",
       "        [ 0.611668  , -0.5722473 ,  1.650226  , ...,  0.861368  ,\n",
       "          0.6609305 ,  1.060108  ],\n",
       "        [-0.18219271,  1.9371303 , -0.28128648, ...,  0.13763778,\n",
       "         -1.5534362 ,  0.22511113],\n",
       "        [-0.29250732,  0.00492136, -0.26993573, ..., -0.97231036,\n",
       "         -0.40363845,  0.25481382]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.35571563, -0.7363194 , -0.01253195, ..., -0.99458677,\n",
       "         -0.15252264, -1.1219375 ],\n",
       "        [-0.17001097,  1.850261  ,  1.89193   , ..., -1.7905267 ,\n",
       "          0.97290504, -0.2909359 ],\n",
       "        [ 0.8425085 ,  0.64755636, -0.5243654 , ...,  0.5032132 ,\n",
       "          0.77456117, -0.72419816],\n",
       "        ...,\n",
       "        [ 0.7209041 ,  0.37950388,  0.44385427, ...,  0.58891636,\n",
       "          0.65098333,  0.4059384 ],\n",
       "        [-0.36241093,  1.6192977 , -0.8029114 , ..., -0.35245523,\n",
       "          0.11418698,  0.04195344],\n",
       "        [-0.3369416 , -0.36151227,  0.01177354, ..., -0.8703543 ,\n",
       "          0.12778537, -0.19126788]],\n",
       "\n",
       "       [[ 0.32439035, -0.38456264, -0.70630467, ..., -0.23906358,\n",
       "          0.19664201, -0.90127456],\n",
       "        [ 0.89963496,  0.3937527 ,  1.2760117 , ...,  0.11968343,\n",
       "          1.0323309 ,  0.98650265],\n",
       "        [ 1.2374885 ,  1.0356061 ,  0.37227547, ...,  0.4517594 ,\n",
       "         -0.06144098,  0.42199478],\n",
       "        ...,\n",
       "        [ 0.29057825,  0.30436048, -0.01241536, ..., -0.330971  ,\n",
       "         -0.46626058,  0.10732313],\n",
       "        [-0.20228617,  0.42224818, -0.5387756 , ..., -0.0871978 ,\n",
       "          0.14011605, -0.04659753],\n",
       "        [-0.7008829 ,  0.37119052,  0.43760434, ..., -0.8467596 ,\n",
       "          0.09969635,  0.17760582]],\n",
       "\n",
       "       [[ 0.61706495, -0.6311574 ,  0.5882819 , ...,  0.25578853,\n",
       "          0.10137073, -0.6305463 ],\n",
       "        [ 0.5784887 ,  0.684261  , -0.1868689 , ..., -0.38747078,\n",
       "          0.26002413, -0.8790766 ],\n",
       "        [ 0.34522086, -1.3735626 ,  1.4259073 , ...,  0.05102051,\n",
       "          0.7485799 , -0.5915235 ],\n",
       "        ...,\n",
       "        [-0.2061053 , -0.74745303, -0.15347806, ...,  0.22044873,\n",
       "          0.00917243, -0.5287509 ],\n",
       "        [-0.4704834 ,  0.7633375 , -0.23268624, ...,  0.46932632,\n",
       "         -0.10799966, -0.6155229 ],\n",
       "        [-0.4210454 , -0.41282377,  0.41764468, ..., -0.12737483,\n",
       "          0.32799986, -0.15843105]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations[\"FG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res[\u001b[39m\"\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res[\"Score\"][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "568ce6a90abe48cd4c71813e2e18d608b5934a77a079188d46a97b4cb4032653"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
